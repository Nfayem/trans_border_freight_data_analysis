{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Chaos to Control: The Power of Data in Freight Logistics Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "<!-- TOC-->\n",
    "\n",
    "* 1. [Business Understanding](#1.-business-understanding)\n",
    "\t* 1.1. [Project Background](#1.1.-project-background)\n",
    "\t* 1.2. [Project Objectives](#1.2.-project-objectives)\n",
    "\t* 1.3. [Stakeholders](#1.3.-stakeholders)\n",
    "\t* 1.4. [Required Deliverables](#1.4.-required-deliverables)\n",
    "\t* 1.5. [Features/Columns](#1.5.-featurescolumns)\n",
    "\t\t* 1.5.1. [Shipment Identification and Trade Information](#1.5.1.-shipment-identification-and-trade-information)\n",
    "\t\t* 1.5.2. [Shipment Origin and Destination Details](#1.5.2.-shipment-origin-and-destination-details)\n",
    "\t\t* 1.5.3. [Transportation and Logistics Information](#1.5.3.-transportation-and-logistics-information)\n",
    "\t\t* 1.5.4. [Economic and Cost Factors](#1.5.4.-economic-and-cost-factors)\n",
    "\t\t* 1.5.5. [Purpose for Feature Categorisation for Freight Analysis](#1.5.5.-purpose-for-feature-categorisation-for-freight-analysis)\n",
    "\t* 1.6. [Hypothesis](#1.6.-hypothesis:)\n",
    "\t* 1.7. [Key Business Questions](#1.7.-key-business-questions)\n",
    "* 2. [Data Understanding](2.-data-understanding)\n",
    "\t* 2.1. [Project Initialization](#2.1.-project-initialization)\n",
    "\t* 2.2. [Data Collection](#2.2.-data-collection)\n",
    "  \t* 2.2.1. [File Concatenation Workflow for 2020 to 2024](#2.2.1.-file-concatenation-workflow-for-2020-to-2024)\n",
    "    \t* 2.2.1.1. [Base Code for Concatenation](#2.2.1.1.-base-code-for-concatenation)\n",
    "    \t* 2.2.1.2. [2020 - 2022 Concatenation](#2.2.1.2.-2020-2022-concatenation)\n",
    "    \t* 2.2.1.3. [2023 Concatenation](#2.2.1.3.-2023-concatenation)\n",
    "    \t* 2.2.1.4. [2024 Concatenation](#2.2.1.4.-2024-concatenation)\n",
    "\t* 2.3. [Exploratory Data Analysis (EDA) and Data Cleaning](#2.3.-exploratory-data-analysis-eda-and-data-cleaning)\n",
    "\t\t* 2.3.1. [Data Quality Assessment & Exploration](#2.3.1.-data-quality-assessment-exploration)\n",
    "\t\t* 2.3.2. [Univariate Analysis](#2.3.2.-univariate-analysis)\n",
    "\t\t* 2.3.3. [Bivariate Analysis](#2.3.3.-bivariate-analysis)\n",
    "\t\t* 2.3.4. [Multivariate Analysis](#2.3.4.-multivariate-analysis)\n",
    "\t\t* 2.3.5. [Handling Missing Values and Feature Engineering](#2.3.5.handling-missing-values-and-feature-engineering)\n",
    "\t\t* 2.3.6. [Analytical Questions](#2.3.6.-analytical-questions)\n",
    "\t\t* 2.3.7. [Hypothesis](#2.3.7.-hypothesis)\n",
    "* 3. [Interactive Dashboard Development](#3.-interactive-dashboard-development)\n",
    "* 4. [References](#4.-references)\n",
    "\n",
    "<!-- /TOC -->\n",
    "\n",
    "<!-- ## Worlflow\n",
    "![A beautiful sunset](https://example.com/sunset.jpg \"Sunset at the beach\") -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#table-of-contents)\n",
    "\n",
    "## 1. Business Understanding\n",
    "\n",
    "### 1.1. Project Background\n",
    "Freight transportation plays a crucial role in global trade and economic stability thus enabling the efficient movement of goods across supply chains. However, inefficiencies, safety risks, and environmental concerns pose significant challenges, requiring data-driven solutions to enhance operational effectiveness.  \n",
    "\n",
    "This project aims to analyze freight movement patterns using data from the **Bureau of Transportation Statistics (BTS)**, applying the **CRISP-DM framework** to systematically explore, and visualize freight logistics data. By identifying inefficiencies, assessing environmental impacts, and evaluating economic disruptions, the study will generate actionable recommendations to optimize freight transportation.  \n",
    "\n",
    "The project operates in a rapidly evolving economic landscape influenced by **fuel price volatility, supply chain disruptions, and shifting consumer demand**. Recent global events, including the COVID-19 pandemic and geopolitical tensions, have underscored the importance of resilient and adaptive freight systems. Studies have shown that the pandemic significantly impacted freight transportation, highlighting the need for robust and flexible logistics networks ([Schofer et al., 2022](https://doi.org/10.1016/J.RTBM.2022.100791)). Geopolitical tensions have also disrupted global supply chains, emphasizing the necessity for adaptive strategies in freight operations ([UN Trade and Development (UNCTAD), 2024](https://unctad.org/news/enhancing-supply-chain-resilience-amid-rising-global-risks)). Through advanced analytics, this study aims to provide insights to enhance efficiency, mitigate risks, and promote sustainability in freight operations.  \n",
    "\n",
    "### 1.2. Project Objectives  \n",
    "The primary goal of this project is to **analyze, optimize, and improve freight transportation systems** through a structured, data-driven approach. The key objectives include:  \n",
    "\n",
    "1. **Freight Movement Analysis:** Identify patterns and trends in freight transportation using BTS data.  \n",
    "2. **Operational Efficiency Optimization:** Detect inefficiencies and propose improvements in logistics and supply chain management.  \n",
    "3. **Environmental Impact Assessment:** Quantify carbon emissions and recommend sustainable freight transport strategies.  \n",
    "4. **Safety and Risk Evaluation:** Assess potential hazards and suggest mitigation measures to enhance freight safety.  \n",
    "5. **Economic Resilience Analysis:** Examine the impact of economic disruptions on freight transport and propose mitigation strategies.  \n",
    "6. **Actionable Recommendations:** Deliver data-backed insights to optimize freight operations and improve decision-making.  \n",
    "\n",
    "### 1.3. Stakeholders  \n",
    "- **Logistics and Supply Chain Managers** – To optimize freight movement and reduce costs.  \n",
    "- **Environmental Policy Makers** – To ensure compliance with sustainability regulations.  \n",
    "- **Transportation Safety Regulators** – To enhance risk mitigation strategies.  \n",
    "- **Economists and Business Analysts** – To understand economic disruptions in freight transport.  \n",
    "- **Technology and Data Science Teams** – To develop predictive models for decision-making.\n",
    "\n",
    "### 1.4. Required Deliverables  \n",
    "- **Visualizations and reports** answering business questions related to freight transportation.  \n",
    "- **Comprehensive documentation** hosted on **GitHub**, including a **README file** detailing methodology and insights.  \n",
    "- **Python scripts and notebooks** used for data analysis, modeling, and visualization.  \n",
    "- **Presentation summarizing objectives, methodology, key findings, and recommendations.** \n",
    "\n",
    "### 1.5. Features/Columns  \n",
    "\n",
    "#### 1.5.1. Shipment Identification and Trade Information  \n",
    "| **Feature**     | **Description**  |  \n",
    "|----------------|--------------------------------------------------------------------------------------------------|  \n",
    "| **YEAR**       | **Year** of the shipment (four-digit AD format). |  \n",
    "| **MONTH**      | **Month** of the shipment (1 - 12). |  \n",
    "| **TRDTYPE**    | Trade type, indicating whether the shipment is an **(1 =export)** or **(2=import)**. |  \n",
    "| **COMMODITY2** | **2-digit commodity code** categorizing the type of goods being transported. |  \n",
    "\n",
    "#### 1.5.2. Shipment Origin and Destination Details \n",
    "| **Feature**   | **Description**  |  \n",
    "|--------------|--------------------------------------------------------------------------------------------------|  \n",
    "| **USASTATE**  | U.S. state code where the freight originates or arrives. |  \n",
    "| **MEXSTATE**  | Mexican state code, applicable when the shipment involves Mexico. |  \n",
    "| **CANPROV**   | Canadian province code, applicable when the shipment involves Canada. |  \n",
    "| **COUNTRY**   | Country code indicating the international origin or destination of the shipment (Canada: **1220**, Mexico: **2010**). |  \n",
    "| **DEPE**      | Port or district code representing the shipment's processing location. |  \n",
    "\n",
    "#### 1.5.3. Transportation and Logistics Information \n",
    "| **Feature**    | **Description**  |  \n",
    "|--------------|--------------------------------------------------------------------------------------------------|  \n",
    "| **DISAGMOT**  | Mode of transportation code specifying how the freight is transported (**1 = Vessel, 3 = Air, 4 = Mail, 5 = Truck, 6 = Rail, 7 = Pipeline, 8 = Other, 9 = Foreign Trade Zones (FTZs)**). |  \n",
    "| **CONTCODE**  | Indicates whether the shipment is **containerized (X)** or **non-containerized (0)**. |  \n",
    "\n",
    "#### 1.5.4. Economic and Cost Factors\n",
    "| **Feature**         | **Description**  |  \n",
    "|--------------------|--------------------------------------------------------------------------------------------------|  \n",
    "| **VALUE**          | Total **value of goods** being shipped, measured in U.S. dollars (USD). |  \n",
    "| **SHIPWT**         | Total **shipping weight** of the goods in kilograms (Kg). |  \n",
    "| **FREIGHT_CHARGES** | **Freight cost** associated with transporting the shipment (in USD). |  \n",
    "| **DF**             | Indicates whether the **merchandise was produced in the U.S. (1 = Domestic) or outside the U.S. (2 = Foreign)**. |  \n",
    "\n",
    "#### 1.5.5. Purpose for Feature Categorisation for Freight Analysis\n",
    "1. **Time-Based Features** → Helps analysts filter by time trends.  \n",
    "2. **Origin & Destination** → Allows clear tracking of movement.  \n",
    "3. **Logistics Features** → Important for transportation insights.  \n",
    "4. **Economic & Cost Factors** → Essential for financial and impact analysis. \n",
    "\n",
    "### 1.6. Hypothesis  \n",
    "\n",
    "**A. Null Hypothesis (H<sub>0</sub>):**  \n",
    "Transportation mode selection, risk management strategies, and sustainability measures have no statistically significant effect on freight transportation efficiency, environmental impact, or resilience.\n",
    "\n",
    "**B. Alternative Hypothesis (H<sub>1</sub>):**  \n",
    "Optimized transportation mode selection, risk management strategies, and sustainability measures significantly improve freight transportation efficiency, reduce environmental impact, and enhance resilience.\n",
    "\n",
    "### 1.7. Key Business Questions  \n",
    "\n",
    "1. **What are the key patterns and trends in freight movement across different transportation modes and trade types?**  \n",
    "   - **Purpose:** To identify inefficiencies and areas for optimization in logistics and supply chain management.  \n",
    "\n",
    "2. **How do different transportation modes impact freight costs and operational efficiency?**  \n",
    "   - **Purpose:** To determine the most cost-effective and efficient transportation methods for different types of goods.  \n",
    "\n",
    "3. **What are the primary contributors to carbon emissions in freight transportation, and how can they be reduced?**  \n",
    "   - **Purpose:** To assess environmental impact and explore sustainable alternatives.  \n",
    "\n",
    "4. **What are the most common risks and safety concerns in freight transport, and how can they be mitigated?**  \n",
    "   - **Purpose:** To enhance freight safety by implementing proactive risk management strategies.  \n",
    "\n",
    "5. **How have economic disruptions (e.g., COVID-19, geopolitical tensions) affected freight movement, and what strategies can improve resilience?**  \n",
    "   - **Purpose:** To develop adaptive strategies that mitigate the impact of economic fluctuations on freight operations.  \n",
    "\n",
    "6. **How do domestic and foreign freight patterns compare, and what implications do they have for trade policies?**  \n",
    "   - **Purpose:** To analyze the effects of domestic vs. international freight trends on economic resilience and strategic decision-making.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#table-of-contents)\n",
    "\n",
    "## 2. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Project Initialisation\n",
    "- Import essential libraries and dependencies for this project, including tools for data manipulation, analysis, and visualization (e.g., Pandas, NumPy, Plotly, etc.).\n",
    "- Set up a reproducible environment for data exploration and ensure consistent configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project initialized with all necessary libraries. Ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 1. Lazy Imports for Prototyping\n",
    "# ==============================\n",
    "import pyforest\n",
    "\n",
    "# ==============================\n",
    "# 2. Automated EDA Tools\n",
    "# ==============================\n",
    "from pydantic import BaseModel \n",
    "from pydantic_settings import BaseSettings\n",
    "from pydantic import Field\n",
    "from ydata_profiling import ProfileReport \n",
    "import sweetviz as sv  \n",
    "\n",
    "# ==============================\n",
    "# 3. Data Handling & Manipulation\n",
    "# ==============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "# 4. Data Visualization\n",
    "# ==============================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# ==============================\n",
    "# 5. Statistical and Scientific Computing\n",
    "# ==============================\n",
    "from scipy.stats import (\n",
    "    chi2_contingency, \n",
    "    ttest_ind, \n",
    "    f_oneway\n",
    ")\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ==============================\n",
    "# 6. Geographic Data & Mapping\n",
    "# ==============================\n",
    "import geopandas as gpd  \n",
    "import folium  \n",
    "\n",
    "# ==============================\n",
    "# 7. Carbon Footprint Estimation\n",
    "# ==============================\n",
    "import co2eq\n",
    "import codecarbon \n",
    "\n",
    "# ==============================\n",
    "# 8. Configurations & Styling\n",
    "# ==============================\n",
    "import os\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Display settings for Pandas\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "# Plot Styling\n",
    "sns.set_theme(style=\"white\", palette=\"pastel\", font=\"sans-serif\", font_scale=1.5)\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "# ==============================\n",
    "# 9. Initialization Code\n",
    "# ==============================\n",
    "print(\"Project initialized with all necessary libraries. Ready for analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data Collection\n",
    "- Load the provided dataset (`dot[number]_[MMYY]` and `dot[number]_ytd_[MMYY]`), ensuring they are properly structured and formatted for analysis.\n",
    "- Verify the integrity of the data by checking file consistency, column definitions, and data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. File Concatenation Workflow for 2020 to 2024\n",
    "**1. 2020–2022:**\n",
    "   - Each year contains **three files**: `dot1_ytd_[final monthyear]`, `dot2_ytd_[final monthyear]`, and `dot3_ytd_[final monthyear]`.  \n",
    "   - **There are no subfolders.**  \n",
    "   - The three files should be concatenated into **one final file per year**:  \n",
    "     - `final_2020 = dot1_ytd_0920 + dot2_ytd_0920 + dot3_ytd_0920`  \n",
    "     - `final_2021 = dot1_ytd_1221 + dot2_ytd_1221 + dot3_ytd_1221`  \n",
    "     - `final_2022 = dot1_ytd_1222 + dot2_ytd_1222 + dot3_ytd_1222`  \n",
    "   - **Concatenate all the final files from 2020 to 2022** into one master file:  \n",
    "     - `final_df = final_2020 + final_2021 + final_2022`\n",
    "\n",
    "**2. 2023:**\n",
    "   - This year contains **three subfolders**: `dot_1`, `dot_2`, and `dot_3`.  \n",
    "   - Each subfolder contains **five files** in the format `dotX_MMYY`.  \n",
    "   - **Concatenate all files within each subfolder into a single file:**  \n",
    "     - `dot1_ytd_1223 = dot1_0923 + dot1_1023 + dot1_1123 + dot1_1223 + dot1_ytd_0823`  \n",
    "     - `dot2_ytd_1223 = dot2_0923 + dot2_1023 + dot2_1123 + dot2_1223 + dot2_ytd_0823`  \n",
    "     - `dot3_ytd_1223 = dot3_0923 + dot3_1023 + dot3_1123 + dot3_1223 + dot3_ytd_0823`  \n",
    "   - **Concatenate the three resulting files into one final file:**  \n",
    "     - `final_2023 = dot1_ytd_1223 + dot2_ytd_1223 + dot3_ytd_1223`  \n",
    "   - **Add the 2023 final files to the master file:**  \n",
    "     - `final_df = final_df + final_2023`\n",
    "\n",
    "**3. 2024:**\n",
    "   - This year contains **three subfolders**: `dot_1`, `dot_2`, and `dot_3`.  \n",
    "   - Each subfolder contains multiple files **(9 for `dot_1` and `dot_2`; 8 for `dot_3` due to missing `dot3_0324`)**.  \n",
    "   - **Concatenate all files within each subfolder into a single file:**  \n",
    "     - `dot1_ytd_0924 = dot1_0124 + dot1_0224 + dot1_0324 + dot1_0424 + dot1_0524 + dot1_0624 + dot1_0724 + dot1_0824 + dot1_0924`  \n",
    "     - `dot2_ytd_0924 = dot2_0124 + dot2_0224 + dot2_0324 + dot2_0424 + dot2_0524 + dot2_0624 + dot2_0724 + dot2_0824 + dot2_0924`  \n",
    "     - `dot3_ytd_0924 = dot3_0124 + dot3_0224 + dot3_0424 + dot3_0524 + dot3_0624 + dot3_0724 + dot3_0824 + dot3_0924` (**excluding dot3_0324**)  \n",
    "   - **Concatenate the three resulting files into one final file:**  \n",
    "     - `final_2024 = dot1_ytd_0924 + dot2_ytd_0924 + dot3_ytd_0924`  \n",
    "   - **Add the 2024 final files to the master file:**  \n",
    "     - `final_df = final_df + final_2024`\n",
    "\n",
    "![Data_Concatenation_Workflow](../assets/dc_flowchart.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1.1. Base Code for Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base directory containing all files\n",
    "base_dir = \"../data\"\n",
    "\n",
    "# Function to read and concatenate CSV files\n",
    "def concat_files(file_list, folder_path):\n",
    "    dfs = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"Loading: {file_path}\")\n",
    "            df = pd.read_csv(file_path)\n",
    "            dfs.append(df)\n",
    "        else:\n",
    "            print(f\"Warning: {file_path} not found!\")\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1.2. 2020 - 2022 Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2020 (Files in `../data\\2020`)...\n",
      "\n",
      "Loading: ../data\\2020\\dot1_ytd_0920.csv\n",
      "Loading: ../data\\2020\\dot2_ytd_0920.csv\n",
      "Loading: ../data\\2020\\dot3_ytd_0920.csv\n",
      "\n",
      "Processing 2021 (Files in `../data\\2021`)...\n",
      "\n",
      "Loading: ../data\\2021\\dot1_ytd_1221.csv\n",
      "Loading: ../data\\2021\\dot2_ytd_1221.csv\n",
      "Loading: ../data\\2021\\dot3_ytd_1221.csv\n",
      "\n",
      "Processing 2022 (Files in `../data\\2022`)...\n",
      "\n",
      "Loading: ../data\\2022\\dot1_ytd_1222.csv\n",
      "Loading: ../data\\2022\\dot2_ytd_1222.csv\n",
      "Loading: ../data\\2022\\dot3_ytd_1222.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRDTYPE</th>\n",
       "      <th>USASTATE</th>\n",
       "      <th>DEPE</th>\n",
       "      <th>DISAGMOT</th>\n",
       "      <th>MEXSTATE</th>\n",
       "      <th>CANPROV</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>SHIPWT</th>\n",
       "      <th>FREIGHT_CHARGES</th>\n",
       "      <th>DF</th>\n",
       "      <th>CONTCODE</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>COMMODITY2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>07XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XA</td>\n",
       "      <td>1220</td>\n",
       "      <td>3302</td>\n",
       "      <td>378</td>\n",
       "      <td>125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XA</td>\n",
       "      <td>1220</td>\n",
       "      <td>133362</td>\n",
       "      <td>137</td>\n",
       "      <td>1563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XA</td>\n",
       "      <td>1220</td>\n",
       "      <td>49960</td>\n",
       "      <td>66</td>\n",
       "      <td>2631</td>\n",
       "      <td>2.0</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XC</td>\n",
       "      <td>1220</td>\n",
       "      <td>21184</td>\n",
       "      <td>3418</td>\n",
       "      <td>795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XM</td>\n",
       "      <td>1220</td>\n",
       "      <td>4253</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925202</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55XX</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1220</td>\n",
       "      <td>3132978</td>\n",
       "      <td>4396</td>\n",
       "      <td>2857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925203</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60XX</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1220</td>\n",
       "      <td>14944</td>\n",
       "      <td>680</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925204</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60XX</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1220</td>\n",
       "      <td>5000</td>\n",
       "      <td>17</td>\n",
       "      <td>450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925205</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70XX</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1220</td>\n",
       "      <td>207760408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925206</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70XX</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>221420268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3925207 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TRDTYPE USASTATE  DEPE  DISAGMOT MEXSTATE CANPROV  COUNTRY  \\\n",
       "0              1       AK  07XX         3      NaN      XA     1220   \n",
       "1              1       AK  20XX         3      NaN      XA     1220   \n",
       "2              1       AK  20XX         3      NaN      XA     1220   \n",
       "3              1       AK  20XX         3      NaN      XC     1220   \n",
       "4              1       AK  20XX         3      NaN      XM     1220   \n",
       "...          ...      ...   ...       ...      ...     ...      ...   \n",
       "3925202        2      NaN  55XX         5      NaN     NaN     1220   \n",
       "3925203        2      NaN  60XX         8      NaN     NaN     1220   \n",
       "3925204        2      NaN  60XX         8      NaN     NaN     1220   \n",
       "3925205        2      NaN  70XX         8      NaN     NaN     1220   \n",
       "3925206        2      NaN  70XX         8      NaN     NaN     2010   \n",
       "\n",
       "             VALUE  SHIPWT  FREIGHT_CHARGES   DF CONTCODE  MONTH  YEAR  \\\n",
       "0             3302     378              125  1.0        X      1  2020   \n",
       "1           133362     137             1563  1.0        X      1  2020   \n",
       "2            49960      66             2631  2.0        X      1  2020   \n",
       "3            21184    3418              795  1.0        X      1  2020   \n",
       "4             4253       2               75  1.0        X      1  2020   \n",
       "...            ...     ...              ...  ...      ...    ...   ...   \n",
       "3925202    3132978    4396             2857  NaN        0     12  2022   \n",
       "3925203      14944     680              150  NaN        0     12  2022   \n",
       "3925204       5000      17              450  NaN        0     12  2022   \n",
       "3925205  207760408       0                0  NaN        0     12  2022   \n",
       "3925206  221420268       0                0  NaN        0     12  2022   \n",
       "\n",
       "         COMMODITY2  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "...             ...  \n",
       "3925202        98.0  \n",
       "3925203        89.0  \n",
       "3925204        98.0  \n",
       "3925205        99.0  \n",
       "3925206        99.0  \n",
       "\n",
       "[3925207 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processing 2020-2022\n",
    "years_2020_2022 = {\n",
    "    \"2020\": [\"dot1_ytd_0920.csv\", \"dot2_ytd_0920.csv\", \"dot3_ytd_0920.csv\"],\n",
    "    \"2021\": [\"dot1_ytd_1221.csv\", \"dot2_ytd_1221.csv\", \"dot3_ytd_1221.csv\"],\n",
    "    \"2022\": [\"dot1_ytd_1222.csv\", \"dot2_ytd_1222.csv\", \"dot3_ytd_1222.csv\"],\n",
    "}\n",
    "\n",
    "final_years = []\n",
    "\n",
    "for year, files in years_2020_2022.items():\n",
    "    folder_path = os.path.join(base_dir, str(year))\n",
    "    print(f\"\\nProcessing {year} (Files in `{folder_path}`)...\\n\")\n",
    "    final_years.append(concat_files(files, folder_path))\n",
    "\n",
    "# Master file up to 2022\n",
    "final_df = pd.concat(final_years, ignore_index=True)\n",
    "\n",
    "# Display results\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1.3. 2023 Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2023 (Files in `../data/2023/dot_x/`)...\n",
      "\n",
      "Processing `dot_1`...\n",
      "\n",
      "Loading: ../data\\2023\\dot_1\\dot1_ytd_0823.csv\n",
      "Loading: ../data\\2023\\dot_1\\dot1_0923.csv\n",
      "Loading: ../data\\2023\\dot_1\\dot1_1023.csv\n",
      "Loading: ../data\\2023\\dot_1\\dot1_1123.csv\n",
      "Loading: ../data\\2023\\dot_1\\dot1_1223.csv\n",
      "\n",
      "Processing `dot_2`...\n",
      "\n",
      "Loading: ../data\\2023\\dot_2\\dot2_ytd_0823.csv\n",
      "Loading: ../data\\2023\\dot_2\\dot2_0923.csv\n",
      "Loading: ../data\\2023\\dot_2\\dot2_1023.csv\n",
      "Loading: ../data\\2023\\dot_2\\dot2_1123.csv\n",
      "Loading: ../data\\2023\\dot_2\\dot2_1223.csv\n",
      "\n",
      "Processing `dot_3`...\n",
      "\n",
      "Loading: ../data\\2023\\dot_3\\dot3_ytd_0823.csv\n",
      "Loading: ../data\\2023\\dot_3\\dot3_0923.csv\n",
      "Loading: ../data\\2023\\dot_3\\dot3_1023.csv\n",
      "Loading: ../data\\2023\\dot_3\\dot3_1123.csv\n",
      "Loading: ../data\\2023\\dot_3\\dot3_1223.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRDTYPE</th>\n",
       "      <th>USASTATE</th>\n",
       "      <th>DEPE</th>\n",
       "      <th>DISAGMOT</th>\n",
       "      <th>MEXSTATE</th>\n",
       "      <th>CANPROV</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>SHIPWT</th>\n",
       "      <th>FREIGHT_CHARGES</th>\n",
       "      <th>DF</th>\n",
       "      <th>CONTCODE</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>COMMODITY2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>07XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XA</td>\n",
       "      <td>1220</td>\n",
       "      <td>3302</td>\n",
       "      <td>378</td>\n",
       "      <td>125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XA</td>\n",
       "      <td>1220</td>\n",
       "      <td>133362</td>\n",
       "      <td>137</td>\n",
       "      <td>1563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XA</td>\n",
       "      <td>1220</td>\n",
       "      <td>49960</td>\n",
       "      <td>66</td>\n",
       "      <td>2631</td>\n",
       "      <td>2.0</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XC</td>\n",
       "      <td>1220</td>\n",
       "      <td>21184</td>\n",
       "      <td>3418</td>\n",
       "      <td>795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XM</td>\n",
       "      <td>1220</td>\n",
       "      <td>4253</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408677</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55XX</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>4750000</td>\n",
       "      <td>9914</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408678</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60XX</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1220</td>\n",
       "      <td>665300</td>\n",
       "      <td>147564</td>\n",
       "      <td>509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408679</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60XX</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>695000</td>\n",
       "      <td>27408</td>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408680</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70XX</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1220</td>\n",
       "      <td>211313370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408681</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70XX</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>219960621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5408682 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TRDTYPE USASTATE  DEPE  DISAGMOT MEXSTATE CANPROV  COUNTRY  \\\n",
       "0              1       AK  07XX         3      NaN      XA     1220   \n",
       "1              1       AK  20XX         3      NaN      XA     1220   \n",
       "2              1       AK  20XX         3      NaN      XA     1220   \n",
       "3              1       AK  20XX         3      NaN      XC     1220   \n",
       "4              1       AK  20XX         3      NaN      XM     1220   \n",
       "...          ...      ...   ...       ...      ...     ...      ...   \n",
       "5408677        2      NaN  55XX         8      NaN     NaN     2010   \n",
       "5408678        2      NaN  60XX         8      NaN     NaN     1220   \n",
       "5408679        2      NaN  60XX         8      NaN     NaN     2010   \n",
       "5408680        2      NaN  70XX         8      NaN     NaN     1220   \n",
       "5408681        2      NaN  70XX         8      NaN     NaN     2010   \n",
       "\n",
       "             VALUE  SHIPWT  FREIGHT_CHARGES   DF CONTCODE  MONTH  YEAR  \\\n",
       "0             3302     378              125  1.0        X      1  2020   \n",
       "1           133362     137             1563  1.0        X      1  2020   \n",
       "2            49960      66             2631  2.0        X      1  2020   \n",
       "3            21184    3418              795  1.0        X      1  2020   \n",
       "4             4253       2               75  1.0        X      1  2020   \n",
       "...            ...     ...              ...  ...      ...    ...   ...   \n",
       "5408677    4750000    9914            10000  NaN        0     12  2023   \n",
       "5408678     665300  147564              509  NaN        0     12  2023   \n",
       "5408679     695000   27408               98  NaN        0     12  2023   \n",
       "5408680  211313370       0                0  NaN        0     12  2023   \n",
       "5408681  219960621       0                0  NaN        0     12  2023   \n",
       "\n",
       "         COMMODITY2  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "...             ...  \n",
       "5408677        98.0  \n",
       "5408678        89.0  \n",
       "5408679        98.0  \n",
       "5408680        99.0  \n",
       "5408681        99.0  \n",
       "\n",
       "[5408682 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processing 2023\n",
    "years_2023 = {\n",
    "    \"2023\": {\n",
    "        \"dot_1\": [\"dot1_ytd_0823.csv\", \"dot1_0923.csv\", \"dot1_1023.csv\", \"dot1_1123.csv\", \"dot1_1223.csv\"],\n",
    "        \"dot_2\": [\"dot2_ytd_0823.csv\", \"dot2_0923.csv\", \"dot2_1023.csv\", \"dot2_1123.csv\", \"dot2_1223.csv\"],\n",
    "        \"dot_3\": [\"dot3_ytd_0823.csv\", \"dot3_0923.csv\", \"dot3_1023.csv\", \"dot3_1123.csv\", \"dot3_1223.csv\"],\n",
    "    }}\n",
    "\n",
    "for year, subfolders in years_2023.items():\n",
    "    print(f\"\\nProcessing {year} (Files in `{base_dir}/{year}/dot_x/`)...\")\n",
    "    subfolder_dfs = []\n",
    "    \n",
    "    for subfolder, files in subfolders.items():\n",
    "        folder_path = os.path.join(base_dir, str(year), subfolder)\n",
    "        print(f\"\\nProcessing `{subfolder}`...\\n\")\n",
    "        subfolder_df = concat_files(files, folder_path)\n",
    "        subfolder_dfs.append(subfolder_df)\n",
    "\n",
    "    # Combine all three `dot_x` datasets into one for the year\n",
    "    if subfolder_dfs:\n",
    "        final_year = pd.concat(subfolder_dfs, ignore_index=True)\n",
    "        final_years.append(final_year)\n",
    "\n",
    "# Master file up to 2023\n",
    "final_df = pd.concat(final_years, ignore_index=True)\n",
    "\n",
    "# Display results\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1.4. 2024 Concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2024 (Files in `../data/2024/dot_x/`)...\n",
      "\n",
      "Processing `dot_1`...\n",
      "\n",
      "Loading: ../data\\2024\\dot_1\\dot1_0124.csv\n",
      "Loading: ../data\\2024\\dot_1\\dot1_0224.csv\n",
      "Loading: ../data\\2024\\dot_1\\dot1_0324.csv\n",
      "Loading: ../data\\2024\\dot_1\\dot1_0424.csv\n",
      "Loading: ../data\\2024\\dot_1\\dot1_0524.csv\n",
      "Loading: ../data\\2024\\dot_1\\dot1_0624.csv\n",
      "Loading: ../data\\2024\\dot_1\\dot1_0724.csv\n",
      "Loading: ../data\\2024\\dot_1\\dot1_0824.csv\n",
      "Loading: ../data\\2024\\dot_1\\dot1_0924.csv\n",
      "\n",
      "Processing `dot_2`...\n",
      "\n",
      "Loading: ../data\\2024\\dot_2\\dot2_0124.csv\n",
      "Loading: ../data\\2024\\dot_2\\dot2_0224.csv\n",
      "Loading: ../data\\2024\\dot_2\\dot2_0324.csv\n",
      "Loading: ../data\\2024\\dot_2\\dot2_0424.csv\n",
      "Loading: ../data\\2024\\dot_2\\dot2_0524.csv\n",
      "Loading: ../data\\2024\\dot_2\\dot2_0624.csv\n",
      "Loading: ../data\\2024\\dot_2\\dot2_0724.csv\n",
      "Loading: ../data\\2024\\dot_2\\dot2_0824.csv\n",
      "Loading: ../data\\2024\\dot_2\\dot2_0924.csv\n",
      "\n",
      "Processing `dot_3`...\n",
      "\n",
      "Loading: ../data\\2024\\dot_3\\dot3_0124.csv\n",
      "Loading: ../data\\2024\\dot_3\\dot3_0224.csv\n",
      "Loading: ../data\\2024\\dot_3\\dot3_0424.csv\n",
      "Loading: ../data\\2024\\dot_3\\dot3_0524.csv\n",
      "Loading: ../data\\2024\\dot_3\\dot3_0624.csv\n",
      "Loading: ../data\\2024\\dot_3\\dot3_0724.csv\n",
      "Loading: ../data\\2024\\dot_3\\dot3_0824.csv\n",
      "Loading: ../data\\2024\\dot_3\\dot3_0924.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>TRDTYPE</th>\n",
       "      <th>COMMODITY2</th>\n",
       "      <th>USASTATE</th>\n",
       "      <th>MEXSTATE</th>\n",
       "      <th>CANPROV</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DEPE</th>\n",
       "      <th>DISAGMOT</th>\n",
       "      <th>CONTCODE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>SHIPWT</th>\n",
       "      <th>FREIGHT_CHARGES</th>\n",
       "      <th>DF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XA</td>\n",
       "      <td>1220</td>\n",
       "      <td>07XX</td>\n",
       "      <td>3</td>\n",
       "      <td>X</td>\n",
       "      <td>3302</td>\n",
       "      <td>378</td>\n",
       "      <td>125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XA</td>\n",
       "      <td>1220</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>X</td>\n",
       "      <td>133362</td>\n",
       "      <td>137</td>\n",
       "      <td>1563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XA</td>\n",
       "      <td>1220</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>X</td>\n",
       "      <td>49960</td>\n",
       "      <td>66</td>\n",
       "      <td>2631</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XC</td>\n",
       "      <td>1220</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>X</td>\n",
       "      <td>21184</td>\n",
       "      <td>3418</td>\n",
       "      <td>795</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XM</td>\n",
       "      <td>1220</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>X</td>\n",
       "      <td>4253</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517220</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1220</td>\n",
       "      <td>55XX</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4384342</td>\n",
       "      <td>7399</td>\n",
       "      <td>1883</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517221</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1220</td>\n",
       "      <td>55XX</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>50211</td>\n",
       "      <td>6350</td>\n",
       "      <td>3500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517222</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1220</td>\n",
       "      <td>60XX</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>793390</td>\n",
       "      <td>80</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517223</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1220</td>\n",
       "      <td>70XX</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>233990301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517224</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>70XX</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>224981722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6517225 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         YEAR  MONTH  TRDTYPE  COMMODITY2 USASTATE MEXSTATE CANPROV  COUNTRY  \\\n",
       "0        2020      1        1         NaN       AK      NaN      XA     1220   \n",
       "1        2020      1        1         NaN       AK      NaN      XA     1220   \n",
       "2        2020      1        1         NaN       AK      NaN      XA     1220   \n",
       "3        2020      1        1         NaN       AK      NaN      XC     1220   \n",
       "4        2020      1        1         NaN       AK      NaN      XM     1220   \n",
       "...       ...    ...      ...         ...      ...      ...     ...      ...   \n",
       "6517220  2024      9        2        98.0      NaN      NaN     NaN     1220   \n",
       "6517221  2024      9        2        98.0      NaN      NaN     NaN     1220   \n",
       "6517222  2024      9        2        89.0      NaN      NaN     NaN     1220   \n",
       "6517223  2024      9        2        99.0      NaN      NaN     NaN     1220   \n",
       "6517224  2024      9        2        99.0      NaN      NaN     NaN     2010   \n",
       "\n",
       "         DEPE  DISAGMOT CONTCODE      VALUE  SHIPWT  FREIGHT_CHARGES   DF  \n",
       "0        07XX         3        X       3302     378              125  1.0  \n",
       "1        20XX         3        X     133362     137             1563  1.0  \n",
       "2        20XX         3        X      49960      66             2631  2.0  \n",
       "3        20XX         3        X      21184    3418              795  1.0  \n",
       "4        20XX         3        X       4253       2               75  1.0  \n",
       "...       ...       ...      ...        ...     ...              ...  ...  \n",
       "6517220  55XX         5        0    4384342    7399             1883  NaN  \n",
       "6517221  55XX         8        0      50211    6350             3500  NaN  \n",
       "6517222  60XX         8        0     793390      80              500  NaN  \n",
       "6517223  70XX         8        0  233990301       0                0  NaN  \n",
       "6517224  70XX         8        0  224981722       0                0  NaN  \n",
       "\n",
       "[6517225 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processing 2024\n",
    "years_2024 = {\n",
    "    \"2024\": {\n",
    "        \"dot_1\": [\"dot1_0124.csv\", \"dot1_0224.csv\", \"dot1_0324.csv\", \"dot1_0424.csv\", \"dot1_0524.csv\",\n",
    "                  \"dot1_0624.csv\", \"dot1_0724.csv\", \"dot1_0824.csv\", \"dot1_0924.csv\"],\n",
    "        \"dot_2\": [\"dot2_0124.csv\", \"dot2_0224.csv\", \"dot2_0324.csv\", \"dot2_0424.csv\", \"dot2_0524.csv\",\n",
    "                  \"dot2_0624.csv\", \"dot2_0724.csv\", \"dot2_0824.csv\", \"dot2_0924.csv\"],\n",
    "        \"dot_3\": [\"dot3_0124.csv\", \"dot3_0224.csv\", \"dot3_0424.csv\", \"dot3_0524.csv\",\n",
    "                  \"dot3_0624.csv\", \"dot3_0724.csv\", \"dot3_0824.csv\", \"dot3_0924.csv\"],\n",
    "    }}\n",
    "\n",
    "for year, subfolders in years_2024.items():\n",
    "    print(f\"\\nProcessing {year} (Files in `{base_dir}/{year}/dot_x/`)...\")\n",
    "    subfolder_dfs = []\n",
    "    \n",
    "    for subfolder, files in subfolders.items():\n",
    "        folder_path = os.path.join(base_dir, str(year), subfolder)\n",
    "        print(f\"\\nProcessing `{subfolder}`...\\n\")\n",
    "        subfolder_df = concat_files(files, folder_path)\n",
    "        subfolder_dfs.append(subfolder_df)\n",
    "\n",
    "    # Combine all three `dot_x` datasets into one for the year\n",
    "    if subfolder_dfs:\n",
    "        final_year = pd.concat(subfolder_dfs, ignore_index=True)\n",
    "        final_years.append(final_year)\n",
    "\n",
    "# Master file up to 2024\n",
    "final_df = pd.concat(final_years, ignore_index=True)\n",
    "\n",
    "# Reorder columns\n",
    "columns = ['YEAR', 'MONTH', 'TRDTYPE', 'COMMODITY2', 'USASTATE', 'MEXSTATE', 'CANPROV', 'COUNTRY', 'DEPE', 'DISAGMOT', 'CONTCODE',\n",
    "            'VALUE', 'SHIPWT', 'FREIGHT_CHARGES', 'DF']\n",
    "final_df = final_df[columns]\n",
    "\n",
    "# Display results\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Exploratory Data Analysis (EDA) and Data Cleaning\n",
    "- Perform a detailed exploration to understand the dataset and address potential issues such as missing values or irrelevant data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Data Quality Assessment & Exploration\n",
    "- **Assess Data Structure**: Use methods like `.info()`, `.head()`, and `.describe()` to evaluate dataset dimensions, data types, and summary statistics.\n",
    "- **Check Duplicates**: Identify and remove duplicate records to ensure data integrity.\n",
    "- **Validate Data Consistency**: Confirm that each variable's values align with expected ranges or categories (e.g., shipment months, and trade types).\n",
    "- **Identify Missing Values**: If no missing values are reported, validate this assumption and confirm completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatype and the number of columns\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame\n",
    "df_train_eda = df_train.copy()\n",
    "\n",
    "# Identify important columns\n",
    "important_columns = ['datetime', 'age', 'job', 'marital', 'education', 'day', 'month', 'year', 'contact', 'campaign', 'duration']\n",
    "\n",
    "\n",
    "# Check for duplicates in the training concatenated data\n",
    "duplicate_count = df_train_eda.duplicated(subset=important_columns, keep=False).sum()\n",
    "duplicates = df_train_eda.duplicated(subset=important_columns, keep='first')\n",
    "\n",
    "# Display results\n",
    "print(f\"Number of duplicated rows in df_train_eda: {duplicate_count}\")\n",
    "df_train_eda[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated rows from training dataset\n",
    "df_train_eda = df_train_eda.drop_duplicates(subset=important_columns, keep='first')\n",
    "\n",
    "# Check for duplicates in the training concatenated data\n",
    "duplicate_count = df_train_eda.duplicated(subset=important_columns, keep=False).sum()\n",
    "duplicates = df_train_eda.duplicated(subset=important_columns, keep='first')\n",
    "\n",
    "# Display results\n",
    "print(f\"Number of duplicated rows in df_train: {duplicate_count}\")\n",
    "df_train_eda[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all column names in the DataFrame\n",
    "columns = final_df.columns\n",
    "\n",
    "# Print details of unique values for each column in the DataFrame\n",
    "for column in columns:\n",
    "    print(f'{column}')  \n",
    "    print(f'There are {final_df[column].unique().size} unique values')  \n",
    "    print(f'{final_df[column].unique()}')  \n",
    "    print('_' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the proportion of missing values\n",
    "missing_percentage = (final_df.isnull().mean() * 100).round(2)\n",
    "\n",
    "# Check for duplicated values\n",
    "duplicate_count = final_df.duplicated(subset=None, keep=False).sum()\n",
    "\n",
    "# Display Results\n",
    "print(\"Proportion of missing values in final_df:\\n\")\n",
    "print(missing_percentage)\n",
    "print(f\"\\nNumber of duplicated rows in final_df: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated rows from training dataset\n",
    "df_train_eda = final_df.drop_duplicates(subset=important_columns, keep='first')\n",
    "\n",
    "# Check for duplicates in the training concatenated data\n",
    "duplicate_count = final_df.duplicated(subset=important_columns, keep=False).sum()\n",
    "duplicates = final_df.duplicated(subset=important_columns, keep='first')\n",
    "\n",
    "# Display results\n",
    "print(f\"Number of duplicated rows in final_df: {duplicate_count}\")\n",
    "final_df[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics for all numeric columns in the DataFrame\n",
    "final_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics for all object (categorical) columns in the DataFrame\n",
    "final_df.describe(include='object').T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. Univariate Analysis\n",
    "- **Explore Individual Features**: Create visualizations such as histograms, bar plots, and box plots to analyze the distributions of numerical and categorical variables.\n",
    "  - Example: Examine the distribution of `VALUE` or analyze the proportion of different `DISAGMOT (Mode of Transportation)` categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3. Bivariate Analysis\n",
    "- **Examine Feature Relationships**: Use scatter plots, bar charts, or box plots to explore pairwise relationships between variables.\n",
    "  - Example: Investigate how `CONTCODE (Containerised or Non Containerised)` varies across different `DISAGMOT` or trade type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4. Multivariate Analysis\n",
    "- **Explore Complex Interactions**: Utilize advanced visualization techniques like heatmaps and pair plots to analyze interactions between multiple variables.\n",
    "  - Example: Assess how economic and cost factores; `VALUE`, `SHIPWT`, `FREIGHT_CHARGES` and `DF` relate to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5. Handling Missing Values and Feature Engineering\n",
    "- **Confirm No Missing Values**: Verify that the dataset is complete, as indicated in the data description.\n",
    "- **Feature Transformation**: Apply transformations to enhance data utility, such as reverse encoding categorical variables or normalizing numerical values.\n",
    "- **Feature Creation**: Convert encoded variables to readable text, normalise numerical values, and create new features like shipment seasonality indicators and economic impact scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.6. Analytical Questions\n",
    "Identify key factors driving successful outcomes, such as optimized logistics strategies and their correlation with improved performance metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.7. Hypothesis\n",
    "Validate hypotheses through statistical methods (e.g., correlation analysis, Chi-square tests) to assess the impact of transportation mode selection, risk management strategies, and sustainability measures on freight transportation efficiency, environmental impact, and resilience. \n",
    "\n",
    "**A. Null Hypothesis (H<sub>0</sub>):**  \n",
    "Transportation mode selection, risk management strategies, and sustainability measures have no statistically significant effect on freight transportation efficiency, environmental impact, or resilience.\n",
    "\n",
    "**B. Alternative Hypothesis (H<sub>1</sub>):**  \n",
    "Optimized transportation mode selection, risk management strategies, and sustainability measures significantly improve freight transportation efficiency, reduce environmental impact, and enhance resilience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#table-of-contents)\n",
    "\n",
    "## 3. Interactive Dashboard Development  \n",
    "Design and implement dynamic visualizations in Power BI to present trends and insights. Dashboards were tailored for stakeholders, including logistics managers, policymakers, and analysts, to facilitate strategic decision-making and measure the effects of strategic interventions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the sampled data to a CSV file\n",
    "# output_file = '../data/Bank_dash_upload.csv'\n",
    "# df_train_eda.to_csv(output_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#table-of-contents)\n",
    "\n",
    "## 4. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Lawrence, M., Homer-Dixon, T., Janzwood, S., Rockstöm, J., Renn, O., & Donges, J. F.** (2024). Global polycrisis: the causal mechanisms of crisis entanglement. *Global Sustainability, 7*, e6. https://doi.org/10.1017/SUS.2024.1  \n",
    "\n",
    "2. **Schofer, J. L., Mahmassani, H. S., & Ng, M. T. M.** (2022). Resilience of U.S. Rail Intermodal Freight during the Covid-19 Pandemic. *Research in Transportation Business & Management, 43*, 100791. https://doi.org/10.1016/J.RTBM.2022.100791  \n",
    "\n",
    "3. **UN Trade and Development (UNCTAD).** (2024). Enhancing supply chain resilience amid rising global risks. [online] Available at: https://unctad.org/news/enhancing-supply-chain-resilience-amid-rising-global-risks.\n",
    "\n",
    "‌\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
